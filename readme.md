# BLG 475E - Software Quality and Testing Project

## Project Overview
This project is part of the BLG 475E - Software Quality and Testing course for the 2024-2025 Spring Term. The project focuses on using Large Language Models (LLMs) to generate code, unit tests, and integration tests. The project is divided into two phases, with specific tasks and deliverables for each phase.

## Authors
- Almila Duru Kavak — 150150703
- Aydan Günaydın — 150200012
- Umut Ural — 150200013

## Project Structure
The project is organized into the following phases:

### Phase 1: Warm-up
- Selecting LLMs
- Selecting Prompts
- Code Generation
- Unit Test Generation
- Analysis and Report

### Phase 2: Extension
- Unit Tests
- Correction and Analysis
- Integration Testing
- Analysis and Report

## Getting Started
To get started with the project, follow these steps:

1. **Clone the Repository:**
   ```bash
   git clone <repository-url>

2. Install Dependencies:
Ensure you have Python installed. You can install the required dependencies using:
   ```bash
   pip3 install pytest

3. Copy
Run the Code:
Navigate to the project directory and run the Python scripts as needed.

### Dataset
The project uses the HumanEval dataset for generating code and tests. The dataset includes descriptions of various programming exercises.
We selected 30 prompts for generating code using LLMs(Gemini, ChatGPT, Mistral AI).  
### Reports
The project requires submitting reports for each phase. Report url: https://www.overleaf.com/project/6807642b2e8d9b1e78de7a89