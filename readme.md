# Comparison of AI Models: Gemini, ChatGPT, and Mistral

## Overview
This project presents a comparative analysis of three popular AI models: Gemini, ChatGPT, and Mistral. The goal is to evaluate their performance and capabilities across various domains, including factual knowledge, contextual reasoning, creative writing, and algorithmic problem-solving. The evaluation is conducted using a series of test cases implemented in Python.

## Table of Contents
- [Overview](#overview)
- [Table of Contents](#table-of-contents)
- [Features](#features)
- [Installation](#installation)
- [Usage](#usage)
- [Test Cases](#test-cases)
- [Results](#results)
- [Conclusion](#conclusion)
- [Contributing](#contributing)
- [License](#license)
- [Acknowledgments](#acknowledgments)

## Features
- Comprehensive evaluation of AI models across multiple criteria.
- Detailed test cases for factual knowledge queries, contextual understanding scenarios, creative writing tasks, and problem-solving questions.
- Analysis of response time, correctness, context retention, creative output quality, and logical reasoning.
- Comparison of performance metrics for each model.
- Python scripts for running test cases and generating results.

## Installation
To run the test cases and generate results, you need to have Python installed on your system. Follow these steps:

1. **Clone the Repository**:
   ```sh
   git clone https://github.com/almiladurukavak/blg475eproject.git
   cd blg475eproject



### @Authors
#### Student Names: <Almila Duru Kavak, Aydan Günaydın, Umut Ural>
####Student IDs: <150150703, 150200012, 150200013>